{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 8\n",
    "N = 16\n",
    "\n",
    "nb_epoch = 2**18\n",
    "batch_size = 256\n",
    "\n",
    "train_SNR_Es = 10\n",
    "test_SNR_Es = np.arange(0,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNNDecoder(torch.nn.Module):\n",
    "    def __init__(self, code_n, code_k):\n",
    "        super(FCNNDecoder, self).__init__()\n",
    "        \n",
    "        self.dec_lays = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=code_n, out_features=128),\n",
    "            torch.nn.Linear(in_features=128, out_features=64),\n",
    "            torch.nn.Linear(in_features=64, out_features=32),\n",
    "            torch.nn.Linear(in_features=32, out_features=code_k)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        logits = self.dec_lays(inputs)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, codewords, infwords, SNR_db_Es, active_cw_indices):        \n",
    "        sigma = torch.sqrt(1/(2*10**(torch.tensor(SNR_db_Es)/10)))\n",
    "        bpsk_sig = -2*codewords[active_cw_indices,:] + 1\n",
    "        noisy_sig = torch.randn_like(bpsk_sig) * sigma + bpsk_sig\n",
    "        self.llrs = 2 * noisy_sig / sigma**2\n",
    "        self.active_infwords = infwords[active_cw_indices,:]\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.llrs.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.llrs[idx], self.active_infwords[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def half_adder(a,b):\n",
    "    s = a ^ b\n",
    "    c = a & b\n",
    "    return s,c\n",
    "\n",
    "def full_adder(a,b,c):\n",
    "    s = (a ^ b) ^ c\n",
    "    c = (a & b) | (c & (a ^ b))\n",
    "    return s,c\n",
    "\n",
    "def add_bool(a,b):\n",
    "    if len(a) != len(b):\n",
    "        raise ValueError('arrays with different length')\n",
    "    k = len(a)\n",
    "    s = np.zeros(k,dtype=bool)\n",
    "    c = False\n",
    "    for i in reversed(range(0,k)):\n",
    "        s[i], c = full_adder(a[i],b[i],c)    \n",
    "    if c:\n",
    "        warnings.warn(\"Addition overflow!\")\n",
    "    return s\n",
    "\n",
    "def inc_bool(a):\n",
    "    k = len(a)\n",
    "    increment = np.hstack((np.zeros(k-1,dtype=bool), np.ones(1,dtype=bool)))\n",
    "    a = add_bool(a,increment)\n",
    "    return a\n",
    "\n",
    "def bitrevorder(x):\n",
    "    m = np.amax(x)\n",
    "    n = np.ceil(np.log2(m)).astype(int)\n",
    "    for i in range(0,len(x)):\n",
    "        x[i] = int('{:0{n}b}'.format(x[i],n=n)[::-1],2)  \n",
    "    return x\n",
    "\n",
    "def int2bin(x,N):\n",
    "    if isinstance(x, list) or isinstance(x, np.ndarray):\n",
    "        binary = np.zeros((len(x),N),dtype='bool')\n",
    "        for i in range(0,len(x)):\n",
    "            binary[i] = np.array([int(j) for j in bin(x[i])[2:].zfill(N)])\n",
    "    else:\n",
    "        binary = np.array([int(j) for j in bin(x)[2:].zfill(N)],dtype=bool)\n",
    "    \n",
    "    return binary\n",
    "\n",
    "def bin2int(b):\n",
    "    if isinstance(b[0], list):\n",
    "        integer = np.zeros((len(b),),dtype=int)\n",
    "        for i in range(0,len(b)):\n",
    "            out = 0\n",
    "            for bit in b[i]:\n",
    "                out = (out << 1) | bit\n",
    "            integer[i] = out\n",
    "    elif isinstance(b, np.ndarray):\n",
    "        if len(b.shape) == 1:\n",
    "            out = 0\n",
    "            for bit in b:\n",
    "                out = (out << 1) | bit\n",
    "            integer = out     \n",
    "        else:\n",
    "            integer = np.zeros((b.shape[0],),dtype=int)\n",
    "            for i in range(0,b.shape[0]):\n",
    "                out = 0\n",
    "                for bit in b[i]:\n",
    "                    out = (out << 1) | bit\n",
    "                integer[i] = out\n",
    "        \n",
    "    return integer\n",
    "\n",
    "def polar_design_awgn(N, k, design_snr_dB):  \n",
    "        \n",
    "    S = 10**(design_snr_dB/10)\n",
    "    z0 = np.zeros(N)\n",
    "\n",
    "    z0[0] = np.exp(-S)\n",
    "    for j in range(1,int(np.log2(N))+1):\n",
    "        u = 2**j\n",
    "        for t in range(0,int(u/2)):\n",
    "            T = z0[t]\n",
    "            z0[t] = 2*T - T**2     # upper channel\n",
    "            z0[int(u/2)+t] = T**2  # lower channel\n",
    "        \n",
    "    # sort into increasing order\n",
    "    idx = np.argsort(z0)\n",
    "        \n",
    "    # select k best channels\n",
    "    idx = np.sort(bitrevorder(idx[0:k]))\n",
    "    \n",
    "    A = np.zeros(N, dtype=bool)\n",
    "    A[idx] = True\n",
    "        \n",
    "    return A\n",
    "\n",
    "def polar_transform_iter(u):\n",
    "\n",
    "    N = len(u)\n",
    "    n = 1\n",
    "    x = np.copy(u)\n",
    "    stages = np.log2(N).astype(int)\n",
    "    for s in range(0,stages):\n",
    "        i = 0\n",
    "        while i < N:\n",
    "            for j in range(0,n):\n",
    "                idx = i+j\n",
    "                x[idx] = x[idx] ^ x[idx+n]\n",
    "            i=i+2*n\n",
    "        n=2*n\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_words(code):\n",
    "    # Create all possible information words\n",
    "    d = np.zeros((2**k,k),dtype=bool)\n",
    "    for i in range(1,2**k):\n",
    "        d[i]= inc_bool(d[i-1])\n",
    "\n",
    "    # Create sets of all possible codewords (codebook)\n",
    "    if code == 'polar':   \n",
    "\n",
    "        A = polar_design_awgn(N, k, design_snr_dB=0)  # logical vector indicating the nonfrozen bit locations \n",
    "        x = np.zeros((2**k, N),dtype=bool)\n",
    "        u = np.zeros((2**k, N),dtype=bool)\n",
    "        u[:,A] = d\n",
    "\n",
    "        for i in range(0,2**k):\n",
    "            x[i] = polar_transform_iter(u[i])\n",
    "        return x, d, A\n",
    "\n",
    "    elif code == 'random':\n",
    "\n",
    "        np.random.seed(4267)   # for a 16bit Random Code (r=0.5) with Hamming distance >= 2\n",
    "        x = np.random.randint(0,2,size=(2**k,N), dtype=bool)\n",
    "        return x, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = 'polar'              # type of code ('random' or 'polar')\n",
    "codewords, inputs, fr_pos = create_words(code)\n",
    "codewords = torch.tensor(codewords, dtype=torch.float32).to(device)\n",
    "inputs = torch.tensor(inputs, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, codewords, inputs, n_epochs, train_indices):\n",
    "    \n",
    "    train_batch_size = train_indices.shape[0]\n",
    "\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "    opt = torch.optim.Adam(model.parameters(),lr=1e-3)\n",
    "\n",
    "    t = trange(n_epochs, desc='', leave=False)\n",
    "    for epoch in t:\n",
    "        train_dataset = NoisyDataset(codewords=codewords, infwords=inputs, \n",
    "                                    SNR_db_Es=train_SNR_Es, active_cw_indices=train_indices)\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=train_batch_size, shuffle=True)\n",
    "\n",
    "        train_ep(model, train_loader, loss_fn, opt)\n",
    "\n",
    "def train_ep(model, train_loader, loss_fn, opt):\n",
    "    model.train()\n",
    "    for llrs, iws in train_loader:\n",
    "        logits = model(llrs)\n",
    "        bce_loss = loss_fn(-1*logits, iws)\n",
    "        opt.zero_grad()\n",
    "        bce_loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "def evaluate(model, codewords, infwords, test_indices, snr_range, max_iter=1e4):\n",
    "    model.eval()\n",
    "\n",
    "    nb_bit_errors = np.zeros_like(snr_range)\n",
    "    nb_frame_errors = np.zeros_like(snr_range)\n",
    "    nb_bits = np.zeros_like(snr_range)\n",
    "    nb_frames = np.zeros_like(snr_range)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        t = tqdm(snr_range, desc='', leave=False)\n",
    "        for i, snr in enumerate(t):\n",
    "            iter_counter = 0\n",
    "            while iter_counter < max_iter:\n",
    "                iter_counter += 1\n",
    "                test_dataset = NoisyDataset(codewords=codewords, infwords=infwords, \n",
    "                                            SNR_db_Es=snr, active_cw_indices=test_indices)\n",
    "                loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_indices.shape[0])\n",
    "                for llrs, iw in loader:\n",
    "                    logits = model(llrs)\n",
    "                    err_vec = torch.fmod((iw + (logits < 0)), 2)\n",
    "                    nb_bit_errors[i] += torch.sum(err_vec)\n",
    "                    nb_frame_errors[i] += torch.sum(torch.sum(err_vec, dim=1) > 0)\n",
    "\n",
    "                nb_bits[i] += (len(loader.dataset) * infwords.shape[1])\n",
    "                nb_frames[i] += len(loader.dataset)\n",
    "\n",
    "            t.set_description(f'EsN0: {snr:.2f} dB', refresh=True)\n",
    "\n",
    "    return nb_bit_errors/nb_bits, nb_frame_errors/nb_frames\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on first 16 codewords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = np.arange(16)\n",
    "test_indices = np.arange(16,2**k)\n",
    "\n",
    "model = FCNNDecoder(code_n=N, code_k=k).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model=model,codewords=codewords,inputs=inputs,n_epochs=nb_epoch,train_indices=train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.50693229, 0.50694271, 0.50774479, 0.50908333, 0.50911458,\n",
       "        0.50863021, 0.50832292]),\n",
       " array([0.99575   , 0.99666667, 0.99658333, 0.99641667, 0.99704167,\n",
       "        0.99695833, 0.997125  ]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model=model, codewords=codewords, infwords=inputs, test_indices=test_indices, snr_range=test_SNR_Es, max_iter=1e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_per_cw(model, codewords, infwords, test_indices, snr_range, max_iter=1e4):\n",
    "    model.eval()\n",
    "\n",
    "    nb_bit_errors = torch.zeros(size=(snr_range.shape[0],test_indices.shape[0]))\n",
    "    nb_frame_errors = torch.zeros(size=(snr_range.shape[0],test_indices.shape[0]))\n",
    "    nb_bits = torch.zeros_like(torch.tensor(snr_range))\n",
    "    nb_frames = torch.zeros_like(torch.tensor(snr_range))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        t = tqdm(snr_range, desc='', leave=False)\n",
    "        for i, snr in enumerate(t):\n",
    "            iter_counter = 0\n",
    "            while iter_counter < max_iter:\n",
    "                iter_counter += 1\n",
    "                test_dataset = NoisyDataset(codewords=codewords, infwords=infwords, \n",
    "                                            SNR_db_Es=snr, active_cw_indices=test_indices)\n",
    "                loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_indices.shape[0])\n",
    "                for llrs, iw in loader:\n",
    "                    logits = model(llrs)\n",
    "                    err_vec = torch.fmod((iw + (logits < 0)), 2)\n",
    "                    nb_bit_errors[i,:] += torch.sum(err_vec,dim=1)\n",
    "                    nb_frame_errors[i,:] += (torch.sum(err_vec, dim=1) > 0)\n",
    "\n",
    "                # nb_bits[i] += infwords.shape[1]\n",
    "                # nb_frames[i] += 1\n",
    "\n",
    "            t.set_description(f'EsN0: {snr:.2f} dB', refresh=True)\n",
    "\n",
    "    # print(nb_bit_errors.shape, nb_bits.repeat(1,test_indices.shape[0]).shape, nb_frame_errors.shape, nb_frames.repeat(1,test_indices.shape[0]).shape)\n",
    "    return nb_bit_errors/max_iter/infwords.shape[1], nb_frame_errors/max_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    }
   ],
   "source": [
    "ber_out, fer_out = evaluate_per_cw(model=model, codewords=codewords, infwords=inputs, test_indices=np.arange(2**k), snr_range=test_SNR_Es, max_iter=1e4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on random 16 codewords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 16\n",
    "np.random.seed(seed=1337)\n",
    "train_indices = np.random.choice(2**k, size=train_size, replace=False)\n",
    "model = FCNNDecoder(code_n=N, code_k=k).to(device)\n",
    "\n",
    "test_indices = np.arange(2**k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    }
   ],
   "source": [
    "train(model=model,codewords=codewords,inputs=inputs,n_epochs=nb_epoch,train_indices=train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    }
   ],
   "source": [
    "ber_out_16, fer_out_16 = evaluate(model=model, codewords=codewords, infwords=inputs, test_indices=test_indices, snr_range=test_SNR_Es, max_iter=1e3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on random 32 codewords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 32\n",
    "np.random.seed(seed=1337)\n",
    "train_indices = np.random.choice(2**k, size=train_size, replace=False)\n",
    "model = FCNNDecoder(code_n=N, code_k=k).to(device)\n",
    "\n",
    "test_indices = np.arange(2**k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    }
   ],
   "source": [
    "train(model=model,codewords=codewords,inputs=inputs,n_epochs=nb_epoch,train_indices=train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    }
   ],
   "source": [
    "ber_out_32, fer_out_32 = evaluate(model=model, codewords=codewords, infwords=inputs, test_indices=test_indices, snr_range=test_SNR_Es, max_iter=1e3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on random 48 codewords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 48\n",
    "np.random.seed(seed=1337)\n",
    "train_indices = np.random.choice(2**k, size=train_size, replace=False)\n",
    "model = FCNNDecoder(code_n=N, code_k=k).to(device)\n",
    "\n",
    "test_indices = np.arange(2**k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|‚ñç         | 12150/262144 [00:32<13:30, 308.49it/s]"
     ]
    }
   ],
   "source": [
    "train(model=model,codewords=codewords,inputs=inputs,n_epochs=nb_epoch,train_indices=train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    }
   ],
   "source": [
    "ber_out_48, fer_out_48 = evaluate(model=model, codewords=codewords, infwords=inputs, test_indices=test_indices, snr_range=test_SNR_Es, max_iter=1e3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on random 64 codewords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 64\n",
    "np.random.seed(seed=1337)\n",
    "train_indices = np.random.choice(2**k, size=train_size, replace=False)\n",
    "model = FCNNDecoder(code_n=N, code_k=k).to(device)\n",
    "\n",
    "test_indices = np.arange(2**k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    }
   ],
   "source": [
    "train(model=model,codewords=codewords,inputs=inputs,n_epochs=nb_epoch,train_indices=train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    }
   ],
   "source": [
    "ber_out_64, fer_out_64 = evaluate(model=model, codewords=codewords, infwords=inputs, test_indices=test_indices, snr_range=test_SNR_Es, max_iter=1e3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on random 86 codewords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 86\n",
    "np.random.seed(seed=1337)\n",
    "train_indices = np.random.choice(2**k, size=train_size, replace=False)\n",
    "model = FCNNDecoder(code_n=N, code_k=k).to(device)\n",
    "\n",
    "test_indices = np.arange(2**k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    }
   ],
   "source": [
    "train(model=model,codewords=codewords,inputs=inputs,n_epochs=nb_epoch,train_indices=train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    }
   ],
   "source": [
    "ber_out_86, fer_out_86 = evaluate(model=model, codewords=codewords, infwords=inputs, test_indices=test_indices, snr_range=test_SNR_Es, max_iter=1e3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on random 128 codewords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 128\n",
    "np.random.seed(seed=1337)\n",
    "train_indices = np.random.choice(2**k, size=train_size, replace=False)\n",
    "model = FCNNDecoder(code_n=N, code_k=k).to(device)\n",
    "\n",
    "test_indices = np.arange(2**k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    }
   ],
   "source": [
    "train(model=model,codewords=codewords,inputs=inputs,n_epochs=nb_epoch,train_indices=train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    }
   ],
   "source": [
    "ber_out_128, fer_out_128 = evaluate(model=model, codewords=codewords, infwords=inputs, test_indices=test_indices, snr_range=test_SNR_Es, max_iter=1e3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on all codewords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 256\n",
    "np.random.seed(seed=1337)\n",
    "train_indices = np.random.choice(2**k, size=train_size, replace=False)\n",
    "model = FCNNDecoder(code_n=N, code_k=k).to(device)\n",
    "\n",
    "test_indices = np.arange(2**k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    }
   ],
   "source": [
    "train(model=model,codewords=codewords,inputs=inputs,n_epochs=nb_epoch,train_indices=train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    }
   ],
   "source": [
    "ber_out_256, fer_out_256 = evaluate(model=model, codewords=codewords, infwords=inputs, test_indices=test_indices, snr_range=test_SNR_Es, max_iter=1e3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gruber-keras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
